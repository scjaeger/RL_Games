{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_board = np.zeros((6, 7), int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State():\n",
    "    def __init__(self, board: np.array, player: int = np.random.randint(1, 3), game_over: bool = False, winner: int = None):\n",
    "        self.board = board\n",
    "        self.player = player\n",
    "        self.winner = winner\n",
    "        self.game_over = game_over\n",
    "        \n",
    "        \n",
    "    def get_actions(self) -> list:\n",
    "        '''\n",
    "        creates a list of column indices that are available for turns\n",
    "        \n",
    "        return:\n",
    "            list of column indices\n",
    "        '''\n",
    "        \n",
    "        # get all columns where the top row is 0 / empty\n",
    "        actions = np.where(self.board[0,:] == 0)\n",
    "        \n",
    "        return list(actions[0])\n",
    "    \n",
    "    \n",
    "    def perform_action(self, column: int):\n",
    "        '''\n",
    "        adds a the player's coin value to the given columns on the board\n",
    "        \n",
    "        Args:\n",
    "            column: Index of the column that is used for this turn\n",
    "        '''\n",
    "        \n",
    "        # set height \n",
    "        height = self.board.shape[0]\n",
    "        \n",
    "        # loop backwards from height to 0\n",
    "        for row in range(height -1, -1, -1):\n",
    "            \n",
    "            # add player number to position if it is empty (0) and break loop\n",
    "            if self.board[row, column] == 0:\n",
    "                \n",
    "                new_board = self.board.copy()\n",
    "                new_board[row, column] = self.player\n",
    "                \n",
    "                winner = self.check_win(new_board, row, column)\n",
    "                \n",
    "                if self.winner or 0 not in new_board:\n",
    "                    game_over = True\n",
    "                else:\n",
    "                    game_over = False\n",
    "                \n",
    "                player = self.change_player()\n",
    "                    \n",
    "                return State(new_board, player, game_over, winner) \n",
    "        \n",
    "        print(\"Error while perform_action\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def check_win(self, board: np.array, row: int, column: int) -> bool:\n",
    "        '''\n",
    "        checks win conditions for current player by checking straight and diagonal lines through the last used position\n",
    "        \n",
    "        Args:\n",
    "            row: row index of the position of the last action\n",
    "            column: column index of the position of the last action\n",
    "        \n",
    "        return:\n",
    "            True if game is won, else False\n",
    "        '''\n",
    "        \n",
    "        # set possible lines through given position on board defined by row and column\n",
    "        lines = {\n",
    "            \"horizontal\": board[row, :],\n",
    "            \"vertical\": board[:, column],\n",
    "            \"diagonal_1\": np.diagonal(board, offset= column - row),\n",
    "            \"diagonal_2\": np.diagonal(np.flipud(board), offset = column - (board.shape[0] - row - 1)),\n",
    "            }\n",
    "        \n",
    "        # loop through possible lines and check for positions marked with current player's number\n",
    "        for key in lines.keys():\n",
    "            # set counter and loop through line\n",
    "            counter = 0\n",
    "            for position in lines[key]:\n",
    "                \n",
    "                # increase counter if player's number is found\n",
    "                if position == self.player:\n",
    "                    counter += 1\n",
    "                    \n",
    "                    # return true and end loop if counter reaches 4\n",
    "                    if counter >= 4:\n",
    "                        # print(f\"{key} winning line at row {row}, column {column}\")\n",
    "                        return self.player\n",
    "                    \n",
    "                # reset counter if another value than the player's number is found \n",
    "                else:\n",
    "                    counter = 0\n",
    "                    \n",
    "        return None  \n",
    "    \n",
    "    \n",
    "    def change_player(self) -> int:\n",
    "        '''\n",
    "        Sets the value of the player to 2 if 1 is given and vice versa\n",
    "        \n",
    "        return:\n",
    "            number of new player\n",
    "        '''\n",
    "        \n",
    "        if self.player == 1:\n",
    "            player = 2\n",
    "        else:\n",
    "            player = 1\n",
    "        \n",
    "        return player"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, parent, state: State):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.edges = self.state.get_actions()\n",
    "        self.children  = []\n",
    "        self.times_tested = 0\n",
    "        self.times_won = 0\n",
    "        self.explored = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_board(state: State, delay: float = 0.01):\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(state.board)\n",
    "    if state.winner:\n",
    "        ax.set_title(f\"player {state.winner} has won\")\n",
    "    elif state.game_over:\n",
    "        ax.set_title(f\"Game Over\")\n",
    "    \n",
    "    display(fig)\n",
    "    clear_output(wait=True)\n",
    "    plt.pause(delay)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCT(node: Node, c: float = np.sqrt(2)) -> int:\n",
    "    '''\n",
    "    chooses an index for a list of nodes based on upper confidence boundary calculation\n",
    "    \n",
    "    Args:\n",
    "        ....\n",
    "    '''\n",
    "    children = [child for child in node.children if not child.explored]\n",
    "        \n",
    "    n_tests = np.array([child.times_tested for child in children])\n",
    "    \n",
    "    n_wins = np.array([child.times_won for child in children])\n",
    "\n",
    "    # calculate uct value\n",
    "    uct = (n_wins/n_tests) + c * np.sqrt(np.emath.log(node.times_tested) / n_tests)\n",
    "    print(uct)\n",
    "    # get index of highest value\n",
    "    node_index = np.argmax(uct)\n",
    "\n",
    "    chosen_node = children[node_index]\n",
    "    \n",
    "    \n",
    "    ################\n",
    "    # MINIMUM FÜR GEGENSPIELER BERÜCKSICHTIGEN\n",
    "    ################\n",
    "    return chosen_node\n",
    "\n",
    "\n",
    "\n",
    "def select_node(node: Node) -> Node:\n",
    "    '''\n",
    "    selects Node to test/ simulate based on their previous outcomes and amount of exploration.\n",
    "    \n",
    "    Args:\n",
    "        root: Starting Node for selection\n",
    "        \n",
    "    return:\n",
    "        Node to elaborate\n",
    "    '''\n",
    "    \n",
    "    # check if untested actions are available\n",
    "    if node.edges:\n",
    "        \n",
    "        # pick a random untested action\n",
    "        edge = random.choice(node.edges)\n",
    "        \n",
    "        # delete chosen action from list\n",
    "        node.edges.remove(edge)\n",
    "        \n",
    "        # create \n",
    "        new_state = node.state.perform_action(edge)\n",
    "        \n",
    "        new_node = Node(node, new_state)\n",
    "        node.children.append(new_node)\n",
    "            \n",
    "    else:\n",
    "    \n",
    "        # get the exploration values of root's children\n",
    "        \n",
    "\n",
    "        uct_node = UCT(node)\n",
    "        \n",
    "        if uct_node.children or uct_node.edges:\n",
    "            new_node = select_node(uct_node)\n",
    "            \n",
    "        else:\n",
    "            print(\"This should not happen\")   \n",
    "            \n",
    "    \n",
    "    return new_node \n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expand_tree(node: Node) -> Node:\n",
    "    \n",
    "#     if node.times_tested > 0:\n",
    "#         node.get_children()\n",
    "        \n",
    "#         if node.children:\n",
    "#             new_node = random.choice(node.children)\n",
    "            \n",
    "#             return new_node\n",
    "        \n",
    "#         else:\n",
    "#             node.explored = True\n",
    "#             ########\n",
    "#             # check/ handover if simulation is necessary\n",
    "#             #######\n",
    "#             # explored maybe added in simulation phase\n",
    "#             #######\n",
    "#             return node\n",
    "        \n",
    "#     else:\n",
    "#         return node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(node: Node) -> bool:\n",
    "    '''\n",
    "    Uses random choices to simulate the outcome of a game\n",
    "    \n",
    "    Args:\n",
    "        Node: Defines the starting situation of the simulation\n",
    "        \n",
    "    Return:\n",
    "        True if active player in given node wins, False if not or draw\n",
    "    '''\n",
    "\n",
    "    state = node.state\n",
    "    \n",
    "    active_player = state.player\n",
    "    \n",
    "    while not state.winner and not state.game_over:\n",
    "        action = random.choice(state.get_actions())\n",
    "        \n",
    "        state = state.perform_action(action)\n",
    "       \n",
    "    return state.winner, state.board\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_full_exploration(node: Node) -> True:\n",
    "    \n",
    "    children = [child for child in node.children if not child.explored]\n",
    "    \n",
    "    if not node.edges and not children:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def backpropagate(node: Node, winner: int) -> None:\n",
    "    \n",
    "    while node.parent:\n",
    "        \n",
    "        node.explored = check_full_exploration(node)\n",
    "        \n",
    "        node.times_tested += 1\n",
    "        if node.state.change_player() == winner:\n",
    "            node.times_won += 1\n",
    "            \n",
    "        node = node.parent\n",
    "        \n",
    "    node.times_tested += 1\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcts(root: Node) -> State:\n",
    "    \n",
    "    t = 0\n",
    "    tree_search = True\n",
    "    \n",
    "    while t < 100 and tree_search:\n",
    "        if select_node(root):\n",
    "            node = select_node(root)\n",
    "            winner, _  = simulate(node)\n",
    "            backpropagate(node, winner)\n",
    "            \n",
    "            t += 1\n",
    "        \n",
    "        else:\n",
    "            tree_search = False\n",
    "    \n",
    "    state = choose_action(root)\n",
    "\n",
    "    return state\n",
    "    \n",
    "def choose_action(root: Node) -> int:\n",
    "    \n",
    "    indices = np.array([]) \n",
    "    values = np.array([])\n",
    "    n_tests = np.array([])\n",
    "    \n",
    "    for i, child in enumerate(root.children):\n",
    "        if child.times_tested > 0:\n",
    "            indices = np.append(indices, i)\n",
    "            values = np.append(values, child.times_won)\n",
    "            n_tests = np.append(n_tests, child.times_tested)\n",
    "\n",
    "    \n",
    "    mean_values = values/ n_tests\n",
    "    max_value = np.argmax(mean_values)\n",
    "    \n",
    "    index = int(indices[max_value])\n",
    "    best_node = root.children[index]\n",
    "\n",
    "    return best_node.state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "\tplayer: 2\n",
      "\tactions: [1, 5, 6]\n",
      "\tgame over/ winner: False/ None\n",
      "\n",
      "after column 5\n",
      "\tplayer: 1\n",
      "\tactions: [1, 5, 6]\n",
      "\tgame over/ winner: False/ None\n",
      "\n",
      "after column 6\n",
      "\tplayer: 2\n",
      "\tactions: [1, 5, 6]\n",
      "\tgame over/ winner: False/ None\n",
      "\n",
      "after column 6\n",
      "\tplayer: 1\n",
      "\tactions: [1, 5]\n",
      "\tgame over/ winner: False/ None\n",
      "\n",
      "after column 5\n",
      "\tplayer: 2\n",
      "\tactions: [1]\n",
      "\tgame over/ winner: False/ None\n",
      "\n",
      "after column 1\n",
      "\tplayer: 1\n",
      "\tactions: []\n",
      "\tgame over/ winner: True/ None\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_wins = False\n",
    "two_wins = False\n",
    "draw = True\n",
    "\n",
    "\n",
    "initial_board = np.zeros((6, 7), int)\n",
    "state = State(board = initial_board, player = 2)\n",
    "\n",
    "state.board = np.array([\n",
    "    [1, 0, 2 ,1 ,1, 0, 0],\n",
    "    [2, 2, 1, 2, 2, 0, 0],\n",
    "    [1, 1, 2, 2, 1, 2, 1],\n",
    "    [2, 2, 1, 1, 1, 2, 2],\n",
    "    [1, 1, 2, 1, 2, 1, 1],\n",
    "    [2, 2, 1, 2, 2, 1, 2],\n",
    "    ])\n",
    "\n",
    "\n",
    "if one_wins:\n",
    "    fig, ax = plt.subplots(ncols=5)\n",
    "    ax[0].imshow(state.board)\n",
    "\n",
    "    print(f\"start\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "\n",
    "    state = state.perform_action(6)\n",
    "    ax[1].imshow(state.board)\n",
    "    print(f\"after column 6\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "\n",
    "    state = state.perform_action(5)\n",
    "    ax[2].imshow(state.board)\n",
    "    print(f\"after column 5\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    state = state.perform_action(5)\n",
    "    ax[3].imshow(state.board)\n",
    "    print(f\"after column 5\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "\n",
    "    state = state.perform_action(6)\n",
    "    ax[4].imshow(state.board)\n",
    "    print(f\"after column 6\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "elif two_wins:\n",
    "    fig, ax = plt.subplots(ncols=4)\n",
    "    ax[0].imshow(state.board)\n",
    "\n",
    "    print(f\"start\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "\n",
    "    state = state.perform_action(6)\n",
    "    ax[1].imshow(state.board)\n",
    "    print(f\"after column 6\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "\n",
    "    state = state.perform_action(6)\n",
    "    ax[2].imshow(state.board)\n",
    "    print(f\"after column 6\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    state = state.perform_action(5)\n",
    "    ax[3].imshow(state.board)\n",
    "    print(f\"after column 5\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "elif draw:\n",
    "    fig, ax = plt.subplots(ncols=6)\n",
    "    ax[0].imshow(state.board)\n",
    "\n",
    "    print(f\"start\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "\n",
    "    state = state.perform_action(5)\n",
    "    ax[1].imshow(state.board)\n",
    "    print(f\"after column 5\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "\n",
    "    state = state.perform_action(6)\n",
    "    ax[2].imshow(state.board)\n",
    "    print(f\"after column 6\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    state = state.perform_action(6)\n",
    "    ax[3].imshow(state.board)\n",
    "    print(f\"after column 6\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    state = state.perform_action(5)\n",
    "    ax[4].imshow(state.board)\n",
    "    print(f\"after column 5\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    state = state.perform_action(1)\n",
    "    ax[5].imshow(state.board)\n",
    "    print(f\"after column 1\\n\\tplayer: {state.player}\\n\\tactions: {state.get_actions()}\\n\\tgame over/ winner: {state.game_over}/ {state.winner}\\n\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagonal upwards: 2 <-- should be 2\n",
      "tested at (0, 4)\n",
      "\n",
      "diagonal downwards: 1 <-- should be 1\n",
      "tested at (4, 3)\n",
      "\n",
      "horizontal: 2 <-- should be 2\n",
      "tested at (5, 6)\n",
      "\n",
      "horizontal: 1 <-- should be 1\n",
      "tested at (1, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_board = np.zeros((6, 7), int)\n",
    "state = State(board = initial_board, player = 2)\n",
    "\n",
    "# diagonal upwards\n",
    "state.board = np.array([\n",
    "    [1, 0, 2 ,1 ,2, 0, 0],\n",
    "    [2, 2, 1, 2, 2, 0, 0],\n",
    "    [1, 1, 2, 2, 1, 2, 1],\n",
    "    [2, 2, 1, 1, 1, 2, 2],\n",
    "    [1, 1, 2, 1, 2, 1, 1],\n",
    "    [2, 2, 1, 2, 2, 1, 2],\n",
    "    ])\n",
    "\n",
    "winner = state.check_win(state.board, 0, 4)\n",
    "print(f\"diagonal upwards: {winner} <-- should be 2\\ntested at (0, 4)\\n\")\n",
    "\n",
    "# diagonal downwards\n",
    "state.player = state.change_player()\n",
    "state.board = np.array([\n",
    "    [1, 0, 2 ,1 ,1, 0, 0],\n",
    "    [2, 2, 1, 2, 2, 0, 0],\n",
    "    [1, 1, 2, 2, 1, 2, 1],\n",
    "    [2, 2, 1, 1, 1, 2, 2],\n",
    "    [1, 1, 2, 1, 2, 1, 1],\n",
    "    [2, 2, 1, 2, 1, 1, 2],\n",
    "    ])\n",
    "\n",
    "winner = state.check_win(state.board, 4, 3)\n",
    "print(f\"diagonal downwards: {winner} <-- should be 1\\ntested at (4, 3)\\n\")\n",
    "\n",
    "# horizontal\n",
    "state.player = state.change_player()\n",
    "state.board = np.array([\n",
    "    [1, 0, 2 ,1 ,1, 0, 0],\n",
    "    [2, 2, 1, 2, 2, 0, 0],\n",
    "    [1, 1, 2, 2, 1, 2, 1],\n",
    "    [2, 2, 1, 1, 1, 2, 2],\n",
    "    [1, 1, 2, 1, 2, 1, 1],\n",
    "    [2, 2, 1, 2, 2, 2, 2],\n",
    "    ])\n",
    "\n",
    "winner = state.check_win(state.board, 5, 6)\n",
    "print(f\"horizontal: {winner} <-- should be 2\\ntested at (5, 6)\\n\")\n",
    "\n",
    "# vertical\n",
    "state.player = state.change_player()\n",
    "state.board = np.array([\n",
    "    [1, 0, 2 ,1 ,1, 0, 0],\n",
    "    [2, 2, 1, 2, 1, 0, 0],\n",
    "    [1, 1, 2, 2, 1, 2, 1],\n",
    "    [2, 2, 1, 1, 1, 2, 2],\n",
    "    [1, 1, 2, 1, 2, 1, 1],\n",
    "    [2, 2, 1, 2, 2, 2, 2],\n",
    "    ])\n",
    "\n",
    "winner = state.check_win(state.board, 1, 4)\n",
    "print(f\"horizontal: {winner} <-- should be 1\\ntested at (1, 4)\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_board = np.zeros((6, 7), int)\n",
    "state = State(board = initial_board, player = 2)\n",
    "\n",
    "state.board = np.array([\n",
    "    [1, 0, 2 ,1 ,0, 0, 0],\n",
    "    [2, 2, 1, 2, 0, 0, 0],\n",
    "    [1, 1, 2, 2, 1, 0, 1],\n",
    "    [2, 2, 1, 1, 2, 1, 2],\n",
    "    [1, 1, 2, 1, 2, 2, 1],\n",
    "    [2, 2, 1, 2, 2, 1, 1],\n",
    "    ])\n",
    "\n",
    "root = Node(None, state)\n",
    "\n",
    "winner, sim_state = simulate(root)\n",
    "\n",
    "plt.imshow(sim_state)\n",
    "print(winner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection - First Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random picks: [0.25  0.236 0.27  0.244]\n",
      "root children: 1\n"
     ]
    }
   ],
   "source": [
    "# setup small board\n",
    "\n",
    "initial_board = np.zeros((4, 4), int)\n",
    "state = State(board = initial_board, player = 1)\n",
    "\n",
    "# check random picks --> should be close to equally distributed\n",
    "picked_nodes = np.zeros_like(state.board)\n",
    "for i in range(500):\n",
    "    node = Node(None, state)\n",
    "    new_node = select_node(node)\n",
    "    picked_nodes = picked_nodes + new_node.state.board\n",
    "\n",
    "picked_nodes = picked_nodes[3, :] / 500\n",
    "print(f\"random picks: {picked_nodes}\")\n",
    "print(f\"root children: {len(node.children)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection - tree expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Expansion\n",
      "Sum of positions of root's cildren: [1 1 1 1] <-- should be [1, 1, 1, 1]\n",
      "times_tested: Root = 4, Sum of children = 4 with 4 children\n",
      "\n",
      "\n",
      "Stats for decision making\n",
      "wins per child node: [1, 0, 0, 0]\n",
      "[2.66510922 1.66510922 1.66510922 1.66510922]\n",
      "[0, 1, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 2, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup small board\n",
    "\n",
    "initial_board = np.zeros((4, 4), int)\n",
    "state = State(board = initial_board, player = 1)\n",
    "\n",
    "node = Node(None, state)\n",
    "\n",
    "# get first 4 calculations\n",
    "for i in range(4):\n",
    "    new_node = select_node(node)\n",
    "    winner, _ = simulate(node)\n",
    "    backpropagate(new_node, winner)\n",
    "    \n",
    "# check if every position is taken\n",
    "positions = np.array([0, 0, 0, 0])\n",
    "times_tested = 0\n",
    "for child in node.children:\n",
    "    positions += child.state.board[3,:]\n",
    "    times_tested += child.times_tested \n",
    "\n",
    "print(\"Before Expansion\")\n",
    "print(f\"Sum of positions of root's cildren: {positions} <-- should be [1, 1, 1, 1]\")\n",
    "print(f\"times_tested: Root = {node.times_tested}, Sum of children = {times_tested} with {len(node.children)} children\")\n",
    "print(\"\\n\")\n",
    "print(\"Stats for decision making\")\n",
    "times_won = [child.times_won for child in node.children]\n",
    "print(f\"wins per child node: {times_won}\")\n",
    "\n",
    "new_node = select_node(node)\n",
    "print(new_node.edges)\n",
    "new_node.state.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SEBAST~1.JAE\\AppData\\Local\\Temp/ipykernel_3384/458820377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# get first 4 calculations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mnew_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mwinner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mbackpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SEBAST~1.JAE\\AppData\\Local\\Temp/ipykernel_3384/430585092.py\u001b[0m in \u001b[0;36mselect_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# check if untested actions are available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# pick a random untested action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Node' object has no attribute 'edges'"
     ]
    }
   ],
   "source": [
    "from treelib import Node, Tree\n",
    "\n",
    "# setup small board\n",
    "\n",
    "initial_board = np.zeros((4, 4), int)\n",
    "state = State(board = initial_board, player = 1)\n",
    "\n",
    "node = Node(None, state)\n",
    "\n",
    "# get first 4 calculations\n",
    "for i in range(100):\n",
    "    new_node = select_node(node)\n",
    "    winner, _ = simulate(node)\n",
    "    backpropagate(new_node, winner)\n",
    "\n",
    "tree = Tree()\n",
    "tree.create_node(f\"wins: {node.times_won}\\ntests: {node.times_tested}\\nboard: {node.state.board}\")\n",
    "\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SEBAST~1.JAE\\AppData\\Local\\Temp/ipykernel_3384/1413026263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"root -> edges {root.edges}, children {len(root.children)}, tests {root.times_tested}, wins {root.times_won}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Node' object has no attribute 'edges'"
     ]
    }
   ],
   "source": [
    "initial_board = np.zeros((6, 7), int)\n",
    "state = State(board = initial_board, player = 2)\n",
    "\n",
    "# state.board = np.array([\n",
    "#     [1, 0, 2 ,0 ,0, 0, 0],\n",
    "#     [2, 2, 1, 0, 0, 0, 0],\n",
    "#     [1, 1, 2, 0, 1, 0, 1],\n",
    "#     [2, 2, 1, 0, 2, 1, 2],\n",
    "#     [1, 1, 2, 1, 2, 2, 1],\n",
    "#     [2, 2, 1, 2, 2, 1, 1],\n",
    "#     ])\n",
    "\n",
    "root = Node(None, state)\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "print(f\"root -> edges {root.edges}, children {len(root.children)}, tests {root.times_tested}, wins {root.times_won}\")\n",
    "   \n",
    "for i in range(500):\n",
    "    node = select_node(root)\n",
    "    winner, sim_state = simulate(node)\n",
    "    backpropagate(node, winner)\n",
    "\n",
    "print(f\"root -> edges {root.edges}, children {len(root.children)}, tests {root.times_tested}, wins {root.times_won}\")  \n",
    "print([child.times_won / child.times_tested for child in root.children])\n",
    "\n",
    "action_values = [child.times_won / child.times_tested for child in root.children]\n",
    "turn_2_state = root.children[np.argmax(action_values)].state\n",
    "\n",
    "plt.imshow(turn_2_state.board)\n",
    "plt.show()\n",
    "\n",
    "for child in root.children:\n",
    "    plt.imshow(child.state.board)\n",
    "    plt.show()\n",
    "    if np.array_equal(turn_2_state.board, child.state.board):\n",
    "        print(\"Action found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "    [1, 0, 2 ,0 ,0, 0, 0],\n",
    "    [2, 2, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 2, 0, 1, 0, 1],\n",
    "    [2, 2, 1, 0, 2, 1, 2],\n",
    "    [1, 1, 2, 1, 2, 2, 1],\n",
    "    [2, 2, 1, 2, 2, 1, 1],\n",
    "    ])\n",
    "\n",
    "b = np.array([\n",
    "    [1, 0, 2 ,0 ,0, 0, 0],\n",
    "    [2, 2, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 2, 0, 1, 0, 1],\n",
    "    [2, 2, 1, 0, 2, 1, 2],\n",
    "    [1, 1, 2, 1, 2, 2, 1],\n",
    "    [2, 2, 1, 2, 2, 1, 1],\n",
    "    ])\n",
    "\n",
    "if np.array_equal(a, b):\n",
    "    print(\"!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f970a4df7d20f1185ed003fdc4111c4356fb1f6e15a77319f2d0dcda97ed7847"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
